{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from datetime import datetime\n",
    "from os import mkdir\n",
    "from os.path import join, exists\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080976, 265)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = pd.read_pickle('../dataset/all_feature.pkl').reset_index(drop=True)\n",
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = '../dataset/lightgbmmodel.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "luck = 123456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LGBMClassifier(nthread=4, silent=False, objective= 'binary', seed=luck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "#     'gamma': [0.05],\n",
    "    #     'n_estimators': [800],\n",
    "    'max_depth': [2, 3, 4],\n",
    "#     'learning_rate': [0.15, 0.3],\n",
    "        'subsample': [0.9],\n",
    "        'colsample_bytree': [0.9],\n",
    "    #     'reg_alpha': [0, 1, 5],\n",
    "    #     'reg_lambda': [0, 1, 4],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_columns = [\n",
    "    x for x in train_features.columns\n",
    "    if x not in [\n",
    "        'orderid', 'uid', 'hotelid', 'basicroomid', 'hotel_roomid', 'roomid',\n",
    "        'orderlabel'\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = model_selection.ShuffleSplit(n_splits=1, test_size=0.2, random_state=luck)\n",
    "clf = model_selection.GridSearchCV(model, parameters, cv=cv, n_jobs=-1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_feture = train_features.sample(1000, random_state=luck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 3 candidates, totalling 3 fits\n",
      "CPU times: user 161 ms, sys: 48.1 ms, total: 209 ms\n",
      "Wall time: 430 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=1, random_state=123456, test_size=0.2, train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=LGBMClassifier(boosting_type='gbdt', colsample_bytree=1, learning_rate=0.1,\n",
       "        max_bin=255, max_depth=-1, min_child_samples=10,\n",
       "        min_child_weight=5, min_split_gain=0, n_estimators=10, nthread=4,\n",
       "        num_leaves=31, objective='binary', reg_alpha=0, reg_lambda=0,\n",
       "        seed=123456, silent=False, subsample=1, subsample_for_bin=50000,\n",
       "        subsample_freq=1),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_depth': [2, 3, 4], 'colsample_bytree': [0.9], 'subsample': [0.9]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(clf_feture[use_columns], clf_feture['orderlabel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # clf.best_params_['n_estimators'] = \n",
    "clf.best_params_['max_depth'] = 12\n",
    "# clf.best_params_['reg_lambda'] = 0.5\n",
    "clf.best_params_['subsample'] = 0.7\n",
    "clf.best_params_['colsample_bytree'] = 0.7\n",
    "# clf.best_params_['n_estimators'] = 1000\n",
    "clf.best_params_['learning_rate'] = 0.1\n",
    "clf.best_params_['num_leaves'] = 24\n",
    "# clf.best_params_['reg_alpha'] = 1\n",
    "# clf.best_params_['min_data_in_leaf'] = 3\n",
    "\n",
    "# clf.best_params_['min_child_weight'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', colsample_bytree=0.7, learning_rate=0.1,\n",
       "        max_bin=255, max_depth=2, min_child_samples=10, min_child_weight=5,\n",
       "        min_split_gain=0, n_estimators=4000, nthread=4, num_leaves=6,\n",
       "        objective='binary', reg_alpha=0, reg_lambda=0, seed=123456,\n",
       "        silent=False, subsample=0.7, subsample_for_bin=50000,\n",
       "        subsample_freq=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LGBMClassifier(\n",
    "    nthread=4,\n",
    "    silent=False,\n",
    "    objective='binary',\n",
    "    seed=luck,\n",
    "#     learning_rate=0.3,\n",
    "    n_estimators=4000,\n",
    "    **clf.best_params_)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_features[use_columns],\n",
    "    train_features['orderlabel'],\n",
    "    test_size=0.33,\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.715686\tvalid_1's auc: 0.71463\n",
      "Train until valid scores didn't improve in 5 rounds.\n",
      "[2]\ttraining's auc: 0.798386\tvalid_1's auc: 0.794022\n",
      "[3]\ttraining's auc: 0.827174\tvalid_1's auc: 0.823519\n",
      "[4]\ttraining's auc: 0.827585\tvalid_1's auc: 0.824023\n",
      "[5]\ttraining's auc: 0.844787\tvalid_1's auc: 0.842096\n",
      "[6]\ttraining's auc: 0.846628\tvalid_1's auc: 0.843199\n",
      "[7]\ttraining's auc: 0.853824\tvalid_1's auc: 0.850673\n",
      "[8]\ttraining's auc: 0.853038\tvalid_1's auc: 0.849359\n",
      "[9]\ttraining's auc: 0.856178\tvalid_1's auc: 0.852489\n",
      "[10]\ttraining's auc: 0.855538\tvalid_1's auc: 0.851531\n",
      "[11]\ttraining's auc: 0.855492\tvalid_1's auc: 0.851569\n",
      "[12]\ttraining's auc: 0.856232\tvalid_1's auc: 0.853156\n",
      "[13]\ttraining's auc: 0.8562\tvalid_1's auc: 0.85272\n",
      "[14]\ttraining's auc: 0.856864\tvalid_1's auc: 0.853731\n",
      "[15]\ttraining's auc: 0.857927\tvalid_1's auc: 0.853983\n",
      "[16]\ttraining's auc: 0.857909\tvalid_1's auc: 0.85474\n",
      "[17]\ttraining's auc: 0.859616\tvalid_1's auc: 0.856141\n",
      "[18]\ttraining's auc: 0.860587\tvalid_1's auc: 0.857395\n",
      "[19]\ttraining's auc: 0.860636\tvalid_1's auc: 0.857315\n",
      "[20]\ttraining's auc: 0.85962\tvalid_1's auc: 0.856357\n",
      "[21]\ttraining's auc: 0.85745\tvalid_1's auc: 0.854549\n",
      "[22]\ttraining's auc: 0.860896\tvalid_1's auc: 0.857754\n",
      "[23]\ttraining's auc: 0.858491\tvalid_1's auc: 0.855694\n",
      "[24]\ttraining's auc: 0.861262\tvalid_1's auc: 0.858269\n",
      "[25]\ttraining's auc: 0.867302\tvalid_1's auc: 0.864607\n",
      "[26]\ttraining's auc: 0.872727\tvalid_1's auc: 0.870439\n",
      "[27]\ttraining's auc: 0.875422\tvalid_1's auc: 0.873306\n",
      "[28]\ttraining's auc: 0.881917\tvalid_1's auc: 0.880009\n",
      "[29]\ttraining's auc: 0.881418\tvalid_1's auc: 0.879206\n",
      "[30]\ttraining's auc: 0.882882\tvalid_1's auc: 0.880943\n",
      "[31]\ttraining's auc: 0.88435\tvalid_1's auc: 0.882275\n",
      "[32]\ttraining's auc: 0.884723\tvalid_1's auc: 0.882803\n",
      "[33]\ttraining's auc: 0.88552\tvalid_1's auc: 0.883608\n",
      "[34]\ttraining's auc: 0.887159\tvalid_1's auc: 0.885385\n",
      "[35]\ttraining's auc: 0.888273\tvalid_1's auc: 0.886301\n",
      "[36]\ttraining's auc: 0.888901\tvalid_1's auc: 0.887106\n",
      "[37]\ttraining's auc: 0.888764\tvalid_1's auc: 0.887122\n",
      "[38]\ttraining's auc: 0.889269\tvalid_1's auc: 0.887619\n",
      "[39]\ttraining's auc: 0.889774\tvalid_1's auc: 0.888154\n",
      "[40]\ttraining's auc: 0.891635\tvalid_1's auc: 0.89003\n",
      "[41]\ttraining's auc: 0.891522\tvalid_1's auc: 0.889959\n",
      "[42]\ttraining's auc: 0.891356\tvalid_1's auc: 0.88985\n",
      "[43]\ttraining's auc: 0.891589\tvalid_1's auc: 0.889956\n",
      "[44]\ttraining's auc: 0.891326\tvalid_1's auc: 0.889745\n",
      "[45]\ttraining's auc: 0.893437\tvalid_1's auc: 0.891824\n",
      "[46]\ttraining's auc: 0.893342\tvalid_1's auc: 0.89187\n",
      "[47]\ttraining's auc: 0.893032\tvalid_1's auc: 0.891592\n",
      "[48]\ttraining's auc: 0.894355\tvalid_1's auc: 0.89294\n",
      "[49]\ttraining's auc: 0.894176\tvalid_1's auc: 0.892848\n",
      "[50]\ttraining's auc: 0.895179\tvalid_1's auc: 0.893667\n",
      "[51]\ttraining's auc: 0.895693\tvalid_1's auc: 0.894286\n",
      "[52]\ttraining's auc: 0.896513\tvalid_1's auc: 0.895084\n",
      "[53]\ttraining's auc: 0.896972\tvalid_1's auc: 0.895409\n",
      "[54]\ttraining's auc: 0.897693\tvalid_1's auc: 0.896086\n",
      "[55]\ttraining's auc: 0.898407\tvalid_1's auc: 0.896801\n",
      "[56]\ttraining's auc: 0.898138\tvalid_1's auc: 0.896568\n",
      "[57]\ttraining's auc: 0.898544\tvalid_1's auc: 0.896902\n",
      "[58]\ttraining's auc: 0.899017\tvalid_1's auc: 0.897268\n",
      "[59]\ttraining's auc: 0.899007\tvalid_1's auc: 0.897317\n",
      "[60]\ttraining's auc: 0.899158\tvalid_1's auc: 0.897483\n",
      "[61]\ttraining's auc: 0.899428\tvalid_1's auc: 0.897658\n",
      "[62]\ttraining's auc: 0.899834\tvalid_1's auc: 0.898085\n",
      "[63]\ttraining's auc: 0.900381\tvalid_1's auc: 0.898676\n",
      "[64]\ttraining's auc: 0.900367\tvalid_1's auc: 0.898645\n",
      "[65]\ttraining's auc: 0.901\tvalid_1's auc: 0.899286\n",
      "[66]\ttraining's auc: 0.90135\tvalid_1's auc: 0.899549\n",
      "[67]\ttraining's auc: 0.901662\tvalid_1's auc: 0.899809\n",
      "[68]\ttraining's auc: 0.90182\tvalid_1's auc: 0.900002\n",
      "[69]\ttraining's auc: 0.902058\tvalid_1's auc: 0.900225\n",
      "[70]\ttraining's auc: 0.90226\tvalid_1's auc: 0.900343\n",
      "[71]\ttraining's auc: 0.902584\tvalid_1's auc: 0.900705\n",
      "[72]\ttraining's auc: 0.902686\tvalid_1's auc: 0.900849\n",
      "[73]\ttraining's auc: 0.902955\tvalid_1's auc: 0.901139\n",
      "[74]\ttraining's auc: 0.90314\tvalid_1's auc: 0.901302\n",
      "[75]\ttraining's auc: 0.903247\tvalid_1's auc: 0.901364\n",
      "[76]\ttraining's auc: 0.903206\tvalid_1's auc: 0.901366\n",
      "[77]\ttraining's auc: 0.903433\tvalid_1's auc: 0.901539\n",
      "[78]\ttraining's auc: 0.903508\tvalid_1's auc: 0.901547\n",
      "[79]\ttraining's auc: 0.903601\tvalid_1's auc: 0.901662\n",
      "[80]\ttraining's auc: 0.903804\tvalid_1's auc: 0.901832\n",
      "[81]\ttraining's auc: 0.903885\tvalid_1's auc: 0.901894\n",
      "[82]\ttraining's auc: 0.904059\tvalid_1's auc: 0.902055\n",
      "[83]\ttraining's auc: 0.904122\tvalid_1's auc: 0.902102\n",
      "[84]\ttraining's auc: 0.904199\tvalid_1's auc: 0.902179\n",
      "[85]\ttraining's auc: 0.904271\tvalid_1's auc: 0.9023\n",
      "[86]\ttraining's auc: 0.904344\tvalid_1's auc: 0.902357\n",
      "[87]\ttraining's auc: 0.904546\tvalid_1's auc: 0.902502\n",
      "[88]\ttraining's auc: 0.904628\tvalid_1's auc: 0.902579\n",
      "[89]\ttraining's auc: 0.904797\tvalid_1's auc: 0.902671\n",
      "[90]\ttraining's auc: 0.904887\tvalid_1's auc: 0.902749\n",
      "[91]\ttraining's auc: 0.905104\tvalid_1's auc: 0.902946\n",
      "[92]\ttraining's auc: 0.905171\tvalid_1's auc: 0.902994\n",
      "[93]\ttraining's auc: 0.905222\tvalid_1's auc: 0.903077\n",
      "[94]\ttraining's auc: 0.905486\tvalid_1's auc: 0.903391\n",
      "[95]\ttraining's auc: 0.905694\tvalid_1's auc: 0.903609\n",
      "[96]\ttraining's auc: 0.90579\tvalid_1's auc: 0.903675\n",
      "[97]\ttraining's auc: 0.906021\tvalid_1's auc: 0.903872\n",
      "[98]\ttraining's auc: 0.905999\tvalid_1's auc: 0.903896\n",
      "[99]\ttraining's auc: 0.906102\tvalid_1's auc: 0.903975\n",
      "[100]\ttraining's auc: 0.906209\tvalid_1's auc: 0.904054\n",
      "[101]\ttraining's auc: 0.90629\tvalid_1's auc: 0.904122\n",
      "[102]\ttraining's auc: 0.906489\tvalid_1's auc: 0.904302\n",
      "[103]\ttraining's auc: 0.906673\tvalid_1's auc: 0.904465\n",
      "[104]\ttraining's auc: 0.906763\tvalid_1's auc: 0.904515\n",
      "[105]\ttraining's auc: 0.906845\tvalid_1's auc: 0.904595\n",
      "[106]\ttraining's auc: 0.906894\tvalid_1's auc: 0.904601\n",
      "[107]\ttraining's auc: 0.907058\tvalid_1's auc: 0.904746\n",
      "[108]\ttraining's auc: 0.907163\tvalid_1's auc: 0.904833\n",
      "[109]\ttraining's auc: 0.907187\tvalid_1's auc: 0.904839\n",
      "[110]\ttraining's auc: 0.907282\tvalid_1's auc: 0.904909\n",
      "[111]\ttraining's auc: 0.907397\tvalid_1's auc: 0.905004\n",
      "[112]\ttraining's auc: 0.907368\tvalid_1's auc: 0.905017\n",
      "[113]\ttraining's auc: 0.907488\tvalid_1's auc: 0.905127\n",
      "[114]\ttraining's auc: 0.907558\tvalid_1's auc: 0.905185\n",
      "[115]\ttraining's auc: 0.907616\tvalid_1's auc: 0.905206\n",
      "[116]\ttraining's auc: 0.907825\tvalid_1's auc: 0.905434\n",
      "[117]\ttraining's auc: 0.908113\tvalid_1's auc: 0.905757\n",
      "[118]\ttraining's auc: 0.908205\tvalid_1's auc: 0.905838\n",
      "[119]\ttraining's auc: 0.908259\tvalid_1's auc: 0.905924\n",
      "[120]\ttraining's auc: 0.90849\tvalid_1's auc: 0.906181\n",
      "[121]\ttraining's auc: 0.908591\tvalid_1's auc: 0.906245\n",
      "[122]\ttraining's auc: 0.908611\tvalid_1's auc: 0.906259\n",
      "[123]\ttraining's auc: 0.908644\tvalid_1's auc: 0.906279\n",
      "[124]\ttraining's auc: 0.908743\tvalid_1's auc: 0.90637\n",
      "[125]\ttraining's auc: 0.908788\tvalid_1's auc: 0.906421\n",
      "[126]\ttraining's auc: 0.908861\tvalid_1's auc: 0.906466\n",
      "[127]\ttraining's auc: 0.908908\tvalid_1's auc: 0.906478\n",
      "[128]\ttraining's auc: 0.908954\tvalid_1's auc: 0.906533\n",
      "[129]\ttraining's auc: 0.909199\tvalid_1's auc: 0.90684\n",
      "[130]\ttraining's auc: 0.909257\tvalid_1's auc: 0.906876\n",
      "[131]\ttraining's auc: 0.909302\tvalid_1's auc: 0.906915\n",
      "[132]\ttraining's auc: 0.909352\tvalid_1's auc: 0.90696\n",
      "[133]\ttraining's auc: 0.909431\tvalid_1's auc: 0.90703\n",
      "[134]\ttraining's auc: 0.909436\tvalid_1's auc: 0.907032\n",
      "[135]\ttraining's auc: 0.909445\tvalid_1's auc: 0.907057\n",
      "[136]\ttraining's auc: 0.909584\tvalid_1's auc: 0.907197\n",
      "[137]\ttraining's auc: 0.909598\tvalid_1's auc: 0.907216\n",
      "[138]\ttraining's auc: 0.909643\tvalid_1's auc: 0.907244\n",
      "[139]\ttraining's auc: 0.90976\tvalid_1's auc: 0.907363\n",
      "[140]\ttraining's auc: 0.909778\tvalid_1's auc: 0.907382\n",
      "[141]\ttraining's auc: 0.909854\tvalid_1's auc: 0.907438\n",
      "[142]\ttraining's auc: 0.909896\tvalid_1's auc: 0.907478\n",
      "[143]\ttraining's auc: 0.909925\tvalid_1's auc: 0.907492\n",
      "[144]\ttraining's auc: 0.909973\tvalid_1's auc: 0.907517\n",
      "[145]\ttraining's auc: 0.910161\tvalid_1's auc: 0.907697\n",
      "[146]\ttraining's auc: 0.910359\tvalid_1's auc: 0.907949\n",
      "[147]\ttraining's auc: 0.910381\tvalid_1's auc: 0.907971\n",
      "[148]\ttraining's auc: 0.910481\tvalid_1's auc: 0.908057\n",
      "[149]\ttraining's auc: 0.9105\tvalid_1's auc: 0.90807\n",
      "[150]\ttraining's auc: 0.910524\tvalid_1's auc: 0.908099\n",
      "[151]\ttraining's auc: 0.910554\tvalid_1's auc: 0.908119\n",
      "[152]\ttraining's auc: 0.910599\tvalid_1's auc: 0.908137\n",
      "[153]\ttraining's auc: 0.910635\tvalid_1's auc: 0.908161\n",
      "[154]\ttraining's auc: 0.910704\tvalid_1's auc: 0.908217\n",
      "[155]\ttraining's auc: 0.910753\tvalid_1's auc: 0.908244\n",
      "[156]\ttraining's auc: 0.910787\tvalid_1's auc: 0.908265\n",
      "[157]\ttraining's auc: 0.910826\tvalid_1's auc: 0.908297\n",
      "[158]\ttraining's auc: 0.910875\tvalid_1's auc: 0.908342\n",
      "[159]\ttraining's auc: 0.910935\tvalid_1's auc: 0.908397\n",
      "[160]\ttraining's auc: 0.910979\tvalid_1's auc: 0.908445\n",
      "[161]\ttraining's auc: 0.911025\tvalid_1's auc: 0.908473\n",
      "[162]\ttraining's auc: 0.91111\tvalid_1's auc: 0.908566\n",
      "[163]\ttraining's auc: 0.911198\tvalid_1's auc: 0.908627\n",
      "[164]\ttraining's auc: 0.911226\tvalid_1's auc: 0.908632\n",
      "[165]\ttraining's auc: 0.911281\tvalid_1's auc: 0.908668\n",
      "[166]\ttraining's auc: 0.911317\tvalid_1's auc: 0.90868\n",
      "[167]\ttraining's auc: 0.911352\tvalid_1's auc: 0.908699\n",
      "[168]\ttraining's auc: 0.911438\tvalid_1's auc: 0.908803\n",
      "[169]\ttraining's auc: 0.911507\tvalid_1's auc: 0.908869\n",
      "[170]\ttraining's auc: 0.911537\tvalid_1's auc: 0.908885\n",
      "[171]\ttraining's auc: 0.911548\tvalid_1's auc: 0.908895\n",
      "[172]\ttraining's auc: 0.911597\tvalid_1's auc: 0.90892\n",
      "[173]\ttraining's auc: 0.911654\tvalid_1's auc: 0.908979\n",
      "[174]\ttraining's auc: 0.911657\tvalid_1's auc: 0.908979\n",
      "[175]\ttraining's auc: 0.911718\tvalid_1's auc: 0.909028\n",
      "[176]\ttraining's auc: 0.911759\tvalid_1's auc: 0.909071\n",
      "[177]\ttraining's auc: 0.911799\tvalid_1's auc: 0.909087\n",
      "[178]\ttraining's auc: 0.911851\tvalid_1's auc: 0.909125\n",
      "[179]\ttraining's auc: 0.911883\tvalid_1's auc: 0.909169\n",
      "[180]\ttraining's auc: 0.911957\tvalid_1's auc: 0.909235\n",
      "[181]\ttraining's auc: 0.911979\tvalid_1's auc: 0.909247\n",
      "[182]\ttraining's auc: 0.91203\tvalid_1's auc: 0.909297\n",
      "[183]\ttraining's auc: 0.912053\tvalid_1's auc: 0.909295\n",
      "[184]\ttraining's auc: 0.912068\tvalid_1's auc: 0.909304\n",
      "[185]\ttraining's auc: 0.912141\tvalid_1's auc: 0.909361\n",
      "[186]\ttraining's auc: 0.912164\tvalid_1's auc: 0.909377\n",
      "[187]\ttraining's auc: 0.912196\tvalid_1's auc: 0.909407\n",
      "[188]\ttraining's auc: 0.912249\tvalid_1's auc: 0.909459\n",
      "[189]\ttraining's auc: 0.912299\tvalid_1's auc: 0.909485\n",
      "[190]\ttraining's auc: 0.912317\tvalid_1's auc: 0.909489\n",
      "[191]\ttraining's auc: 0.912333\tvalid_1's auc: 0.909499\n",
      "[192]\ttraining's auc: 0.912352\tvalid_1's auc: 0.909522\n",
      "[193]\ttraining's auc: 0.912389\tvalid_1's auc: 0.909544\n",
      "[194]\ttraining's auc: 0.912405\tvalid_1's auc: 0.909556\n",
      "[195]\ttraining's auc: 0.912482\tvalid_1's auc: 0.909663\n",
      "[196]\ttraining's auc: 0.912525\tvalid_1's auc: 0.909692\n",
      "[197]\ttraining's auc: 0.91257\tvalid_1's auc: 0.909736\n",
      "[198]\ttraining's auc: 0.912648\tvalid_1's auc: 0.90976\n",
      "[199]\ttraining's auc: 0.91269\tvalid_1's auc: 0.909793\n",
      "[200]\ttraining's auc: 0.912717\tvalid_1's auc: 0.909797\n",
      "[201]\ttraining's auc: 0.91276\tvalid_1's auc: 0.909842\n",
      "[202]\ttraining's auc: 0.912779\tvalid_1's auc: 0.909842\n",
      "[203]\ttraining's auc: 0.912843\tvalid_1's auc: 0.909899\n",
      "[204]\ttraining's auc: 0.91285\tvalid_1's auc: 0.90991\n",
      "[205]\ttraining's auc: 0.91289\tvalid_1's auc: 0.909954\n",
      "[206]\ttraining's auc: 0.912975\tvalid_1's auc: 0.909986\n",
      "[207]\ttraining's auc: 0.91299\tvalid_1's auc: 0.909992\n",
      "[208]\ttraining's auc: 0.913034\tvalid_1's auc: 0.910031\n",
      "[209]\ttraining's auc: 0.913079\tvalid_1's auc: 0.910063\n",
      "[210]\ttraining's auc: 0.913107\tvalid_1's auc: 0.910088\n",
      "[211]\ttraining's auc: 0.913118\tvalid_1's auc: 0.910088\n",
      "[212]\ttraining's auc: 0.913126\tvalid_1's auc: 0.910086\n",
      "[213]\ttraining's auc: 0.913147\tvalid_1's auc: 0.910099\n",
      "[214]\ttraining's auc: 0.913276\tvalid_1's auc: 0.910265\n",
      "[215]\ttraining's auc: 0.913301\tvalid_1's auc: 0.910282\n",
      "[216]\ttraining's auc: 0.913331\tvalid_1's auc: 0.910319\n",
      "[217]\ttraining's auc: 0.913364\tvalid_1's auc: 0.910348\n",
      "[218]\ttraining's auc: 0.913394\tvalid_1's auc: 0.91037\n",
      "[219]\ttraining's auc: 0.913405\tvalid_1's auc: 0.910376\n",
      "[220]\ttraining's auc: 0.913422\tvalid_1's auc: 0.91039\n",
      "[221]\ttraining's auc: 0.913442\tvalid_1's auc: 0.910397\n",
      "[222]\ttraining's auc: 0.913463\tvalid_1's auc: 0.910403\n",
      "[223]\ttraining's auc: 0.91348\tvalid_1's auc: 0.910422\n",
      "[224]\ttraining's auc: 0.913488\tvalid_1's auc: 0.910418\n",
      "[225]\ttraining's auc: 0.913539\tvalid_1's auc: 0.910495\n",
      "[226]\ttraining's auc: 0.913568\tvalid_1's auc: 0.910518\n",
      "[227]\ttraining's auc: 0.913612\tvalid_1's auc: 0.910551\n",
      "[228]\ttraining's auc: 0.913625\tvalid_1's auc: 0.910547\n",
      "[229]\ttraining's auc: 0.913658\tvalid_1's auc: 0.910559\n",
      "[230]\ttraining's auc: 0.91381\tvalid_1's auc: 0.910723\n",
      "[231]\ttraining's auc: 0.913868\tvalid_1's auc: 0.910795\n",
      "[232]\ttraining's auc: 0.913868\tvalid_1's auc: 0.910801\n",
      "[233]\ttraining's auc: 0.913888\tvalid_1's auc: 0.910808\n",
      "[234]\ttraining's auc: 0.91399\tvalid_1's auc: 0.910946\n",
      "[235]\ttraining's auc: 0.913975\tvalid_1's auc: 0.910919\n",
      "[236]\ttraining's auc: 0.914004\tvalid_1's auc: 0.910934\n",
      "[237]\ttraining's auc: 0.914015\tvalid_1's auc: 0.910942\n",
      "[238]\ttraining's auc: 0.914071\tvalid_1's auc: 0.910993\n",
      "[239]\ttraining's auc: 0.914125\tvalid_1's auc: 0.91103\n",
      "[240]\ttraining's auc: 0.91413\tvalid_1's auc: 0.911026\n",
      "[241]\ttraining's auc: 0.914154\tvalid_1's auc: 0.911057\n",
      "[242]\ttraining's auc: 0.914201\tvalid_1's auc: 0.911098\n",
      "[243]\ttraining's auc: 0.914355\tvalid_1's auc: 0.911248\n",
      "[244]\ttraining's auc: 0.914365\tvalid_1's auc: 0.911266\n",
      "[245]\ttraining's auc: 0.914375\tvalid_1's auc: 0.911253\n",
      "[246]\ttraining's auc: 0.914389\tvalid_1's auc: 0.911275\n",
      "[247]\ttraining's auc: 0.914405\tvalid_1's auc: 0.911283\n",
      "[248]\ttraining's auc: 0.914432\tvalid_1's auc: 0.911302\n",
      "[249]\ttraining's auc: 0.914473\tvalid_1's auc: 0.911341\n",
      "[250]\ttraining's auc: 0.914496\tvalid_1's auc: 0.911363\n",
      "[251]\ttraining's auc: 0.914491\tvalid_1's auc: 0.911356\n",
      "[252]\ttraining's auc: 0.914517\tvalid_1's auc: 0.91137\n",
      "[253]\ttraining's auc: 0.914551\tvalid_1's auc: 0.911388\n",
      "[254]\ttraining's auc: 0.914587\tvalid_1's auc: 0.911411\n",
      "[255]\ttraining's auc: 0.914599\tvalid_1's auc: 0.911418\n",
      "[256]\ttraining's auc: 0.914604\tvalid_1's auc: 0.91142\n",
      "[257]\ttraining's auc: 0.914633\tvalid_1's auc: 0.91145\n",
      "[258]\ttraining's auc: 0.914661\tvalid_1's auc: 0.911476\n",
      "[259]\ttraining's auc: 0.914675\tvalid_1's auc: 0.911468\n",
      "[260]\ttraining's auc: 0.914704\tvalid_1's auc: 0.911497\n",
      "[261]\ttraining's auc: 0.914741\tvalid_1's auc: 0.91154\n",
      "[262]\ttraining's auc: 0.914753\tvalid_1's auc: 0.911541\n",
      "[263]\ttraining's auc: 0.914804\tvalid_1's auc: 0.911584\n",
      "[264]\ttraining's auc: 0.914827\tvalid_1's auc: 0.911611\n",
      "[265]\ttraining's auc: 0.914831\tvalid_1's auc: 0.911606\n",
      "[266]\ttraining's auc: 0.914847\tvalid_1's auc: 0.91161\n",
      "[267]\ttraining's auc: 0.914865\tvalid_1's auc: 0.911628\n",
      "[268]\ttraining's auc: 0.914879\tvalid_1's auc: 0.911644\n",
      "[269]\ttraining's auc: 0.914961\tvalid_1's auc: 0.911738\n",
      "[270]\ttraining's auc: 0.914975\tvalid_1's auc: 0.911753\n",
      "[271]\ttraining's auc: 0.915006\tvalid_1's auc: 0.911778\n",
      "[272]\ttraining's auc: 0.915028\tvalid_1's auc: 0.911792\n",
      "[273]\ttraining's auc: 0.915028\tvalid_1's auc: 0.911767\n",
      "[274]\ttraining's auc: 0.915049\tvalid_1's auc: 0.911782\n",
      "[275]\ttraining's auc: 0.915063\tvalid_1's auc: 0.911783\n",
      "[276]\ttraining's auc: 0.91518\tvalid_1's auc: 0.911901\n",
      "[277]\ttraining's auc: 0.91518\tvalid_1's auc: 0.911892\n",
      "[278]\ttraining's auc: 0.915199\tvalid_1's auc: 0.911904\n",
      "[279]\ttraining's auc: 0.915222\tvalid_1's auc: 0.911919\n",
      "[280]\ttraining's auc: 0.915242\tvalid_1's auc: 0.91193\n",
      "[281]\ttraining's auc: 0.915252\tvalid_1's auc: 0.911925\n",
      "[282]\ttraining's auc: 0.915274\tvalid_1's auc: 0.911932\n",
      "[283]\ttraining's auc: 0.915299\tvalid_1's auc: 0.911959\n",
      "[284]\ttraining's auc: 0.915312\tvalid_1's auc: 0.911962\n",
      "[285]\ttraining's auc: 0.915329\tvalid_1's auc: 0.911966\n",
      "[286]\ttraining's auc: 0.915341\tvalid_1's auc: 0.911962\n",
      "[287]\ttraining's auc: 0.91536\tvalid_1's auc: 0.911978\n",
      "[288]\ttraining's auc: 0.915369\tvalid_1's auc: 0.911984\n",
      "[289]\ttraining's auc: 0.915384\tvalid_1's auc: 0.911985\n",
      "[290]\ttraining's auc: 0.915398\tvalid_1's auc: 0.912006\n",
      "[291]\ttraining's auc: 0.915408\tvalid_1's auc: 0.912018\n",
      "[292]\ttraining's auc: 0.91544\tvalid_1's auc: 0.912061\n",
      "[293]\ttraining's auc: 0.915439\tvalid_1's auc: 0.912064\n",
      "[294]\ttraining's auc: 0.915448\tvalid_1's auc: 0.912067\n",
      "[295]\ttraining's auc: 0.915457\tvalid_1's auc: 0.912059\n",
      "[296]\ttraining's auc: 0.915473\tvalid_1's auc: 0.912067\n",
      "[297]\ttraining's auc: 0.915529\tvalid_1's auc: 0.91212\n",
      "[298]\ttraining's auc: 0.915545\tvalid_1's auc: 0.912136\n",
      "[299]\ttraining's auc: 0.91556\tvalid_1's auc: 0.912143\n",
      "[300]\ttraining's auc: 0.915569\tvalid_1's auc: 0.912146\n",
      "[301]\ttraining's auc: 0.915574\tvalid_1's auc: 0.912152\n",
      "[302]\ttraining's auc: 0.915601\tvalid_1's auc: 0.912159\n",
      "[303]\ttraining's auc: 0.915621\tvalid_1's auc: 0.912151\n",
      "[304]\ttraining's auc: 0.915648\tvalid_1's auc: 0.912166\n",
      "[305]\ttraining's auc: 0.915646\tvalid_1's auc: 0.912168\n",
      "[306]\ttraining's auc: 0.915651\tvalid_1's auc: 0.912187\n",
      "[307]\ttraining's auc: 0.915664\tvalid_1's auc: 0.912189\n",
      "[308]\ttraining's auc: 0.915673\tvalid_1's auc: 0.912192\n",
      "[309]\ttraining's auc: 0.91571\tvalid_1's auc: 0.912219\n",
      "[310]\ttraining's auc: 0.915731\tvalid_1's auc: 0.912235\n",
      "[311]\ttraining's auc: 0.91573\tvalid_1's auc: 0.91224\n",
      "[312]\ttraining's auc: 0.915742\tvalid_1's auc: 0.912238\n",
      "[313]\ttraining's auc: 0.915781\tvalid_1's auc: 0.912274\n",
      "[314]\ttraining's auc: 0.915787\tvalid_1's auc: 0.912272\n",
      "[315]\ttraining's auc: 0.915808\tvalid_1's auc: 0.912281\n",
      "[316]\ttraining's auc: 0.915817\tvalid_1's auc: 0.912288\n",
      "[317]\ttraining's auc: 0.915843\tvalid_1's auc: 0.912305\n",
      "[318]\ttraining's auc: 0.91585\tvalid_1's auc: 0.912305\n",
      "[319]\ttraining's auc: 0.915857\tvalid_1's auc: 0.912297\n",
      "[320]\ttraining's auc: 0.915869\tvalid_1's auc: 0.9123\n",
      "[321]\ttraining's auc: 0.915888\tvalid_1's auc: 0.912314\n",
      "[322]\ttraining's auc: 0.915913\tvalid_1's auc: 0.912344\n",
      "[323]\ttraining's auc: 0.915934\tvalid_1's auc: 0.912357\n",
      "[324]\ttraining's auc: 0.915961\tvalid_1's auc: 0.912362\n",
      "[325]\ttraining's auc: 0.915987\tvalid_1's auc: 0.912375\n",
      "[326]\ttraining's auc: 0.916003\tvalid_1's auc: 0.912376\n",
      "[327]\ttraining's auc: 0.916026\tvalid_1's auc: 0.912394\n",
      "[328]\ttraining's auc: 0.916042\tvalid_1's auc: 0.912401\n",
      "[329]\ttraining's auc: 0.916082\tvalid_1's auc: 0.912431\n",
      "[330]\ttraining's auc: 0.916105\tvalid_1's auc: 0.912445\n",
      "[331]\ttraining's auc: 0.91612\tvalid_1's auc: 0.912463\n",
      "[332]\ttraining's auc: 0.916138\tvalid_1's auc: 0.912487\n",
      "[333]\ttraining's auc: 0.916173\tvalid_1's auc: 0.912513\n",
      "[334]\ttraining's auc: 0.916181\tvalid_1's auc: 0.912519\n",
      "[335]\ttraining's auc: 0.916187\tvalid_1's auc: 0.912518\n",
      "[336]\ttraining's auc: 0.916207\tvalid_1's auc: 0.912526\n",
      "[337]\ttraining's auc: 0.916204\tvalid_1's auc: 0.912516\n",
      "[338]\ttraining's auc: 0.916219\tvalid_1's auc: 0.912516\n",
      "[339]\ttraining's auc: 0.916241\tvalid_1's auc: 0.912533\n",
      "[340]\ttraining's auc: 0.916243\tvalid_1's auc: 0.91253\n",
      "[341]\ttraining's auc: 0.916254\tvalid_1's auc: 0.91253\n",
      "[342]\ttraining's auc: 0.916273\tvalid_1's auc: 0.912532\n",
      "[343]\ttraining's auc: 0.916288\tvalid_1's auc: 0.912538\n",
      "[344]\ttraining's auc: 0.916299\tvalid_1's auc: 0.91254\n",
      "[345]\ttraining's auc: 0.916312\tvalid_1's auc: 0.912549\n",
      "[346]\ttraining's auc: 0.916328\tvalid_1's auc: 0.912555\n",
      "[347]\ttraining's auc: 0.916336\tvalid_1's auc: 0.912547\n",
      "[348]\ttraining's auc: 0.916345\tvalid_1's auc: 0.912547\n",
      "[349]\ttraining's auc: 0.916382\tvalid_1's auc: 0.912577\n",
      "[350]\ttraining's auc: 0.916397\tvalid_1's auc: 0.91259\n",
      "[351]\ttraining's auc: 0.916431\tvalid_1's auc: 0.912612\n",
      "[352]\ttraining's auc: 0.916473\tvalid_1's auc: 0.91264\n",
      "[353]\ttraining's auc: 0.916494\tvalid_1's auc: 0.912653\n",
      "[354]\ttraining's auc: 0.916505\tvalid_1's auc: 0.912655\n",
      "[355]\ttraining's auc: 0.916507\tvalid_1's auc: 0.912656\n",
      "[356]\ttraining's auc: 0.916517\tvalid_1's auc: 0.91266\n",
      "[357]\ttraining's auc: 0.916525\tvalid_1's auc: 0.912661\n",
      "[358]\ttraining's auc: 0.916537\tvalid_1's auc: 0.912665\n",
      "[359]\ttraining's auc: 0.916547\tvalid_1's auc: 0.912678\n",
      "[360]\ttraining's auc: 0.916576\tvalid_1's auc: 0.912677\n",
      "[361]\ttraining's auc: 0.916587\tvalid_1's auc: 0.912675\n",
      "[362]\ttraining's auc: 0.916607\tvalid_1's auc: 0.912687\n",
      "[363]\ttraining's auc: 0.916618\tvalid_1's auc: 0.91269\n",
      "[364]\ttraining's auc: 0.916628\tvalid_1's auc: 0.912677\n",
      "[365]\ttraining's auc: 0.916637\tvalid_1's auc: 0.912678\n",
      "[366]\ttraining's auc: 0.916676\tvalid_1's auc: 0.912702\n",
      "[367]\ttraining's auc: 0.91668\tvalid_1's auc: 0.912697\n",
      "[368]\ttraining's auc: 0.916699\tvalid_1's auc: 0.912703\n",
      "[369]\ttraining's auc: 0.916714\tvalid_1's auc: 0.912713\n",
      "[370]\ttraining's auc: 0.916729\tvalid_1's auc: 0.912741\n",
      "[371]\ttraining's auc: 0.916738\tvalid_1's auc: 0.912746\n",
      "[372]\ttraining's auc: 0.916771\tvalid_1's auc: 0.912768\n",
      "[373]\ttraining's auc: 0.916784\tvalid_1's auc: 0.912773\n",
      "[374]\ttraining's auc: 0.91679\tvalid_1's auc: 0.912767\n",
      "[375]\ttraining's auc: 0.916806\tvalid_1's auc: 0.912778\n",
      "[376]\ttraining's auc: 0.916817\tvalid_1's auc: 0.912782\n",
      "[377]\ttraining's auc: 0.916835\tvalid_1's auc: 0.912809\n",
      "[378]\ttraining's auc: 0.916842\tvalid_1's auc: 0.912808\n",
      "[379]\ttraining's auc: 0.916846\tvalid_1's auc: 0.91281\n",
      "[380]\ttraining's auc: 0.916864\tvalid_1's auc: 0.912831\n",
      "[381]\ttraining's auc: 0.916863\tvalid_1's auc: 0.912825\n",
      "[382]\ttraining's auc: 0.916875\tvalid_1's auc: 0.912816\n",
      "[383]\ttraining's auc: 0.916918\tvalid_1's auc: 0.912864\n",
      "[384]\ttraining's auc: 0.916947\tvalid_1's auc: 0.912889\n",
      "[385]\ttraining's auc: 0.916964\tvalid_1's auc: 0.912898\n",
      "[386]\ttraining's auc: 0.916975\tvalid_1's auc: 0.912898\n",
      "[387]\ttraining's auc: 0.916985\tvalid_1's auc: 0.912899\n",
      "[388]\ttraining's auc: 0.916998\tvalid_1's auc: 0.912915\n",
      "[389]\ttraining's auc: 0.917016\tvalid_1's auc: 0.912927\n",
      "[390]\ttraining's auc: 0.917028\tvalid_1's auc: 0.912929\n",
      "[391]\ttraining's auc: 0.917039\tvalid_1's auc: 0.912933\n",
      "[392]\ttraining's auc: 0.917054\tvalid_1's auc: 0.912937\n",
      "[393]\ttraining's auc: 0.917061\tvalid_1's auc: 0.912937\n",
      "[394]\ttraining's auc: 0.917077\tvalid_1's auc: 0.912947\n",
      "[395]\ttraining's auc: 0.917097\tvalid_1's auc: 0.912963\n",
      "[396]\ttraining's auc: 0.917111\tvalid_1's auc: 0.912981\n",
      "[397]\ttraining's auc: 0.917113\tvalid_1's auc: 0.912969\n",
      "[398]\ttraining's auc: 0.917111\tvalid_1's auc: 0.912964\n",
      "[399]\ttraining's auc: 0.917134\tvalid_1's auc: 0.91297\n",
      "[400]\ttraining's auc: 0.917142\tvalid_1's auc: 0.912966\n",
      "[401]\ttraining's auc: 0.917155\tvalid_1's auc: 0.912977\n",
      "Early stopping, best iteration is:\n",
      "[396]\ttraining's auc: 0.917111\tvalid_1's auc: 0.912981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', colsample_bytree=0.7, learning_rate=0.1,\n",
       "        max_bin=255, max_depth=2, min_child_samples=10, min_child_weight=5,\n",
       "        min_split_gain=0, n_estimators=4000, nthread=4, num_leaves=6,\n",
       "        objective='binary', reg_alpha=0, reg_lambda=0, seed=123456,\n",
       "        silent=False, subsample=0.7, subsample_for_bin=50000,\n",
       "        subsample_freq=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "    early_stopping_rounds=10,\n",
    "    eval_metric='auc',\n",
    "    verbose=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_score(model, X_train, train_features):\n",
    "    result = model.predict_proba(X_train)[:, 1]\n",
    "    train_features['prob'] = np.nan\n",
    "    train_features.loc[X_train.index, 'prob'] = result\n",
    "    train_x = train_features.loc[X_train.index, ['orderid', 'prob', 'orderlabel']]\n",
    "    train_x.sort_values('prob', ascending=False, inplace=True)\n",
    "    finall_result_x = train_x.drop_duplicates(['orderid'])\n",
    "    train_score = finall_result_x.orderlabel.mean()\n",
    "    print(train_score)\n",
    "    return train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32124472784\n"
     ]
    }
   ],
   "source": [
    "train_score = get_score(model, X_train, train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19883493838\n"
     ]
    }
   ],
   "source": [
    "test_score = get_score(model, X_test, train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models/31-2339-importance.txt'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not exists('models'):\n",
    "    mkdir('models')\n",
    "model_importance_path = join('models', datetime.now().strftime('%d-%H%M-importance.txt'))\n",
    "model_importance_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importance_df = pd.DataFrame(model.feature_importances_, index=use_columns)\n",
    "\n",
    "importance_df.sort_values(0, ascending=False, inplace=True)\n",
    "importance_df.to_csv(model_importance_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'max_depth: 2,colsample_bytree: 0.7,subsample: 0.7,learning_rate: 0.1,num_leaves: 6'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parms = ','.join(['{}: {}'.format(k, v) for k, v in clf.best_params_.items()])\n",
    "parms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31-23-39:  online  ??  test_score  0.19883493838  train_score  0.32124472784  model_train  0.917111235022  model_test  0.912981448034  n  396  params  max_depth: 2,colsample_bytree: 0.7,subsample: 0.7,learning_rate: 0.1,num_leaves: 6\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now().strftime('%d-%H-%M:'),\n",
    "      'online', '??',\n",
    "     'test_score', test_score,\n",
    "     'train_score', train_score,\n",
    "     'model_train', model.best_score['training']['auc'],\n",
    "     'model_test', model.best_score['valid_1']['auc'],\n",
    "     'n', model.best_iteration,\n",
    "     'params', parms, end='\\n', sep='  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(datetime.now().strftime('%d-%H-%M:'),\n",
    "      'online', '??',\n",
    "     'test_score', test_score,\n",
    "     'train_score', train_score,\n",
    "     'model_train', model.best_score['training']['auc'],\n",
    "     'model_test', model.best_score['valid_1']['auc'],\n",
    "     'n', model.best_iteration,\n",
    "     'params', parms, end='\\n', sep=',', file=open('lgb_result.txt', 'a+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(model, open(model_path, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
